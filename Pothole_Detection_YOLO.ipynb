{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1eX5K12BkJxpuj8QUCUqNQMjqTdB5FDqQ",
      "authorship_tag": "ABX9TyOvR2HHC1gBtrkBbn+E2uwS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supravosengupta23/supravosengupta23/blob/main/Pothole_Detection_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a69qSI7j7MHe",
        "outputId": "b6dd5761-c721-43ea-a496-71d21c55bdc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Installing YOLO and dependencies...\n",
            "‚úÖ Installation completed!\n",
            "üñ•Ô∏è  CUDA available: True\n",
            "üöÄ GPU: Tesla T4\n",
            "üíæ GPU Memory: 14.7 GB\n"
          ]
        }
      ],
      "source": [
        "# Install YOLO and dependencies\n",
        "print(\"üîß Installing YOLO and dependencies...\")\n",
        "!pip install ultralytics -q\n",
        "!pip install roboflow -q\n",
        "!pip install easyocr -q\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Colab specific imports\n",
        "from google.colab import drive, files\n",
        "from IPython.display import display, Image as IPImage\n",
        "\n",
        "print(\"‚úÖ Installation completed!\")\n",
        "\n",
        "# Check GPU availability\n",
        "print(f\"üñ•Ô∏è  CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  GPU not available - Enable it: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TA1SXW3iKDPi",
        "outputId": "b9d6d736-2be0-4cc5-d773-b59bb4e6025f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize YOLO model\n",
        "print(\"üì¶ Loading YOLO model...\")\n",
        "model = YOLO('yolov8s.pt')  # Downloads automatically on first run\n",
        "\n",
        "print(\"‚úÖ YOLO model loaded successfully!\")\n",
        "print(\"Available model sizes: yolov8n.pt (fastest), yolov8s.pt (balanced), yolov8m.pt, yolov8l.pt, yolov8x.pt (most accurate)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0QfBG3iHtw3",
        "outputId": "f5f8bc38-bf33-4b56-eb4d-63369e202b9f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Loading YOLO model...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21.5MB 67.7MB/s 0.3s\n",
            "‚úÖ YOLO model loaded successfully!\n",
            "Available model sizes: yolov8n.pt (fastest), yolov8s.pt (balanced), yolov8m.pt, yolov8l.pt, yolov8x.pt (most accurate)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 1: Upload ZIP file directly\n",
        "print(\"üì§ Upload your dataset ZIP file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract uploaded ZIP\n",
        "import zipfile\n",
        "for filename in uploaded.keys():\n",
        "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall('dataset')\n",
        "    print(f\"‚úÖ Extracted {filename} to 'dataset' folder\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "dnNPzBOiIvZW",
        "outputId": "d75ee1de-c62b-4672-8066-2371041f8d0d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì§ Upload your dataset ZIP file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-94d3d06e-c4d8-4f87-a99e-bb8a9f261aef\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-94d3d06e-c4d8-4f87-a99e-bb8a9f261aef\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Pothole detection.v1i.yolov8.zip to Pothole detection.v1i.yolov8.zip\n",
            "‚úÖ Extracted Pothole detection.v1i.yolov8.zip to 'dataset' folder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üì¶ Loading YOLO model for pothole detection...\")\n",
        "\n",
        "# YOLOv8m is recommended for potholes (better accuracy for road textures)\n",
        "model = YOLO('yolov8m.pt')\n",
        "\n",
        "print(\"‚úÖ Model loaded!\")\n",
        "print(\"üï≥Ô∏è YOLOv8m chosen for optimal pothole detection performance\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jbA5DrCJmH4",
        "outputId": "a257cae6-5d2e-4d23-dd10-65d605183a8d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Loading YOLO model for pothole detection...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 49.7MB 361.6MB/s 0.1s\n",
            "‚úÖ Model loaded!\n",
            "üï≥Ô∏è YOLOv8m chosen for optimal pothole detection performance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "def setup_pothole_training(dataset_path=\"/content/dataset\"):\n",
        "    \"\"\"Setup pothole detection training configuration\"\"\"\n",
        "\n",
        "    # Create data.yaml for pothole detection\n",
        "    config = {\n",
        "        'path': str(Path(dataset_path).absolute()),\n",
        "        'train': 'train/images',      # Adjust if your structure is different\n",
        "        'val': 'valid/images',        # Adjust if your structure is different\n",
        "        'test': 'test/images',        # Optional\n",
        "        'nc': 1,                      # Number of classes (just potholes)\n",
        "        'names': {0: 'pothole'}       # Class names\n",
        "    }\n",
        "\n",
        "    # Save configuration\n",
        "    yaml_path = 'pothole_config.yaml'\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        yaml.dump(config, f, default_flow_style=False)\n",
        "\n",
        "    print(\"‚úÖ Pothole training configuration created!\")\n",
        "    print(f\"üìÑ Config saved as: {yaml_path}\")\n",
        "\n",
        "    return yaml_path\n",
        "\n",
        "# Setup configuration\n",
        "# Assuming DATASET_PATH is defined elsewhere or you can use the default\n",
        "# If DATASET_PATH is not defined, you can call the function without arguments:\n",
        "config_file = setup_pothole_training()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBzyiNvjLst6",
        "outputId": "d3b4a45d-5152-4b14-c15a-5b665c685b58"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Pothole training configuration created!\n",
            "üìÑ Config saved as: pothole_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üöÄ Starting Pothole Detection Training...\")\n",
        "\n",
        "# Training with pothole-optimized parameters\n",
        "results = model.train(\n",
        "    data=\"/content/pothole_config.yaml\",\n",
        "    epochs=100,                    # Adjust based on your needs\n",
        "    imgsz=640,                     # Image size\n",
        "    batch=16,                      # Batch size (reduce if GPU memory issues)\n",
        "    lr0=0.01,                      # Learning rate\n",
        "    patience=20,                   # Early stopping patience\n",
        "    save=True,\n",
        "    cache=True,\n",
        "    device='auto',                 # Use GPU if available\n",
        "    project='pothole_training',\n",
        "    name='experiment_1',\n",
        "\n",
        "    # POTHOLE-SPECIFIC OPTIMIZATIONS\n",
        "    degrees=10.0,                  # Road angle variations (more than license plates)\n",
        "    translate=0.1,                 # Position variations\n",
        "    scale=0.3,                     # Size variations for different distances\n",
        "    perspective=0.0003,            # Camera angle variations (vehicle mounted)\n",
        "    flipud=0.0,                    # No vertical flip for roads\n",
        "    fliplr=0.5,                    # Horizontal flip OK\n",
        "    mosaic=1.0,                    # Excellent for small pothole detection\n",
        "    mixup=0.15,                    # Helps with road texture learning\n",
        "    copy_paste=0.3,                # Pothole augmentation\n",
        "\n",
        "    # Loss function weights (important for precise pothole boundaries)\n",
        "    cls=0.5,                       # Classification loss\n",
        "    box=7.5,                       # Box regression loss (crucial for potholes)\n",
        "    dfl=1.5,                       # Distribution focal loss\n",
        "\n",
        "    plots=True,                    # Generate training plots\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Training completed!\")\n",
        "print(\"üìÅ Best model saved at: pothole_training/experiment_1/weights/best.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN45ixN4MEsW",
        "outputId": "a301a6af-0edd-42c0-8296-04eb42fea0c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting Pothole Detection Training...\n",
            "Ultralytics 8.3.218 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:auto (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.3, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/pothole_config.yaml, degrees=10.0, deterministic=True, device=auto, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.15, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=experiment_1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0003, plots=True, pose=12.0, pretrained=True, profile=False, project=pothole_training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/pothole_training/experiment_1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.3, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 117.9MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
            "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 232.7MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1057.4¬±360.3 MB/s, size: 61.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/train/labels... 316 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 316/316 2.5Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/train/labels.cache\n",
            "WARNING ‚ö†Ô∏è cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.4GB RAM): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 316/316 337.9it/s 0.9s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 628.8¬±453.4 MB/s, size: 79.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/valid/labels... 102 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 102/102 1.4Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/valid/labels.cache\n",
            "WARNING ‚ö†Ô∏è cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB RAM): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 102/102 123.3it/s 0.8s\n",
            "Plotting labels to /content/pothole_training/experiment_1/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/pothole_training/experiment_1\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      6.38G      2.106      3.046      2.093         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 20/20 1.7it/s 12.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.5it/s 2.7s\n",
            "                   all        102        278      0.141     0.0504     0.0284     0.0157\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100      6.64G      1.837      2.277      1.902         56        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 20/20 2.0it/s 10.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 3.0it/s 1.3s\n",
            "                   all        102        278    0.00533      0.263    0.00311    0.00105\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100      6.64G      1.906      2.272      1.965         74        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 20/20 1.9it/s 10.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.7it/s 1.5s\n",
            "                   all        102        278    0.00203      0.223    0.00134   0.000369\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100      6.63G      1.983      2.374      2.035         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 20/20 2.0it/s 10.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.9it/s 1.4s\n",
            "                   all        102        278    0.00211      0.223    0.00139   0.000384\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100      6.64G      1.931       2.34      2.021         50        640: 35% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 7/20 1.8it/s 4.0s<7.1s"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "def test_pothole_model(model_path, test_image_path):\n",
        "    \"\"\"Test the trained pothole detection model\"\"\"\n",
        "\n",
        "    # Load trained model\n",
        "    trained_model = YOLO(model_path)\n",
        "\n",
        "    # Run inference (lower confidence threshold for potholes)\n",
        "    results = trained_model(test_image_path, conf=0.25)  # Lower threshold for subtle potholes\n",
        "\n",
        "    # Display results\n",
        "    result_img = results[0].plot()\n",
        "    result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(result_img)\n",
        "    plt.axis('off')\n",
        "    plt.title('Pothole Detection Results')\n",
        "    plt.show()\n",
        "\n",
        "    # Print detection details\n",
        "    boxes = results[0].boxes\n",
        "    if boxes is not None:\n",
        "        print(f\"üï≥Ô∏è Detected {len(boxes)} pothole(s):\")\n",
        "        for i, box in enumerate(boxes):\n",
        "            conf = box.conf[0].item()\n",
        "            x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "            area = (x2-x1) * (y2-y1)\n",
        "            print(f\"  Pothole {i+1}: Confidence={conf:.3f}, Area={area:.0f}px¬≤\")\n",
        "    else:\n",
        "        print(\"‚úÖ No potholes detected\")\n",
        "\n",
        "# Test the model (update paths as needed)\n",
        "model_path = '/content/pothole_training/experiment_1/weights/best.pt'\n",
        "test_image = '/content/dataset/test/images'  # Update this with an actual image file!\n",
        "\n",
        "# Uncomment to test:\n",
        "test_pothole_model(model_path, test_image)"
      ],
      "metadata": {
        "id": "ABbr_02aNNMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_training_results():\n",
        "    \"\"\"Display training results and metrics\"\"\"\n",
        "\n",
        "    # Plot training results\n",
        "    results_img_path = 'pothole_training/experiment_1/results.png'\n",
        "\n",
        "    if Path(results_img_path).exists():\n",
        "        img = plt.imread(results_img_path)\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title('Pothole Detection Training Results')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Training results plot not found\")\n",
        "\n",
        "# Show results\n",
        "show_training_results()\n",
        "\n",
        "print(\"üéâ Pothole Detection Training Complete!\")\n"
      ],
      "metadata": {
        "id": "8MFNRuIUTNUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p0X1CsjeUb8x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}